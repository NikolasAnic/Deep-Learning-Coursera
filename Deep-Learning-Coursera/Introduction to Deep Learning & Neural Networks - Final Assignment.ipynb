{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning & Neural Networks w/ Keras \n",
    "# - Final Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this markdown file, I will build a regression model through a neural network. The basis of the exercise is a construction data set obtained from cocl. In the exercise, I will attempt to predict the concrete strength as accurately as possible. The measure for accuracy will be the mean-squared error. \n",
    "\n",
    "I will use the Keras library to compute the artificial neural network and exectute the training, testing and evaluation process. \n",
    "\n",
    "By doing so, I will indicate each specific step and follow the respective way: \n",
    "\n",
    "1. Loading the data\n",
    "2. Transforming predictor and dependent variable (indicator) data \n",
    "3. Creating an artificial neural network function according to the prerequisites given \n",
    "4. Run the data on the neural network \n",
    "5. Evaluate the accuracy of the model\n",
    "6. Re-run the model on the data to improve its accuracy and display the evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: Build a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transforming predictor and dependent variable (indicator) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_col = concrete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = concrete_data[concrete_data_col[concrete_data_col != \"Strength\"]]\n",
    "indicator = concrete_data[concrete_data_col[concrete_data_col == \"Strength\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the predictors: \n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Train-Test Splitting the data: \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, indicator, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neural Network Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 893us/step - loss: 1457.8717\n",
      "10/10 [==============================] - 0s 915us/step - loss: 650.6755\n",
      "10/10 [==============================] - 0s 826us/step - loss: 216.8064\n",
      "10/10 [==============================] - 0s 771us/step - loss: 105.4534\n",
      "10/10 [==============================] - 0s 893us/step - loss: 98.8871\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 158.3754\n",
      "10/10 [==============================] - 0s 755us/step - loss: 150.2598\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 176.6778\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 84.8389\n",
      "10/10 [==============================] - 0s 840us/step - loss: 121.3217\n",
      "10/10 [==============================] - 0s 854us/step - loss: 110.7076\n",
      "10/10 [==============================] - 0s 838us/step - loss: 1490.2261\n",
      "10/10 [==============================] - 0s 857us/step - loss: 132.9179\n",
      "10/10 [==============================] - 0s 801us/step - loss: 1097.1389\n",
      "10/10 [==============================] - 0s 948us/step - loss: 113.6142\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 110.9230\n",
      "10/10 [==============================] - 0s 922us/step - loss: 133.5394\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 105.2150\n",
      "10/10 [==============================] - 0s 980us/step - loss: 215.9049\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 338.9612\n",
      "10/10 [==============================] - 0s 914us/step - loss: 105.0621\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 342.6824\n",
      "10/10 [==============================] - 0s 927us/step - loss: 123.9343\n",
      "10/10 [==============================] - 0s 817us/step - loss: 127.0910\n",
      "10/10 [==============================] - 0s 794us/step - loss: 123.9015\n",
      "10/10 [==============================] - 0s 887us/step - loss: 105.1092\n",
      "10/10 [==============================] - 0s 859us/step - loss: 149.0709\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 157.7913\n",
      "10/10 [==============================] - 0s 971us/step - loss: 127.7202\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 276.0524\n",
      "10/10 [==============================] - 0s 830us/step - loss: 150.3188\n",
      "10/10 [==============================] - 0s 880us/step - loss: 1216.8333\n",
      "10/10 [==============================] - 0s 883us/step - loss: 84.8161\n",
      "10/10 [==============================] - 0s 822us/step - loss: 353.3842\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 154.9745\n",
      "10/10 [==============================] - 0s 973us/step - loss: 874.8325\n",
      "10/10 [==============================] - 0s 783us/step - loss: 520.8569\n",
      "10/10 [==============================] - 0s 890us/step - loss: 319.0031\n",
      "10/10 [==============================] - 0s 941us/step - loss: 85.0957\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 645.0754\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 87.9119\n",
      "10/10 [==============================] - 0s 910us/step - loss: 168.1113\n",
      "10/10 [==============================] - 0s 863us/step - loss: 129.5261\n",
      "10/10 [==============================] - 0s 782us/step - loss: 321.8948\n",
      "10/10 [==============================] - 0s 939us/step - loss: 100.4014\n",
      "10/10 [==============================] - 0s 884us/step - loss: 242.8185\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 112.8512\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 235.4211\n",
      "10/10 [==============================] - 0s 931us/step - loss: 123.5207\n",
      "10/10 [==============================] - 0s 880us/step - loss: 634.8085\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i in range(1,51):\n",
    "    def regression_model(): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "    model.fit(predictors, indicator, validation_data=(X_test, y_test), epochs = 50, verbose = 0)\n",
    "    scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "    rows.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value:  0    305.423741\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0    349.409952\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows = pd.DataFrame(rows)\n",
    "print(\"Mean Value: \", rows.mean(), \"\\n\" \"Standard Deviation Value: \", rows.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Normalizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can pretty much do everything as we did before, but we normalize the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "indicator_norm = (indicator - indicator.mean()) / indicator.std()\n",
    "n_cols = n_cols = predictors_norm.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors_norm, indicator_norm, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 1229.7679\n",
      "10/10 [==============================] - 0s 914us/step - loss: 1216.2473\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1222.6937\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1115.8411\n",
      "10/10 [==============================] - 0s 873us/step - loss: 1091.4019\n",
      "10/10 [==============================] - 0s 908us/step - loss: 1255.9419\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 777.2266\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1207.0674\n",
      "10/10 [==============================] - 0s 739us/step - loss: 1053.2834\n",
      "10/10 [==============================] - 0s 921us/step - loss: 920.3679\n",
      "10/10 [==============================] - 0s 731us/step - loss: 1177.1418\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1218.2131\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1120.1945\n",
      "10/10 [==============================] - 0s 952us/step - loss: 1128.1427\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1123.0933\n",
      "10/10 [==============================] - 0s 859us/step - loss: 729.6952\n",
      "10/10 [==============================] - 0s 966us/step - loss: 1157.4012\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 654.2798\n",
      "10/10 [==============================] - 0s 976us/step - loss: 1155.4500\n",
      "10/10 [==============================] - 0s 805us/step - loss: 1122.8494\n",
      "10/10 [==============================] - 0s 925us/step - loss: 1231.0875\n",
      "10/10 [==============================] - 0s 912us/step - loss: 1236.1570\n",
      "10/10 [==============================] - 0s 732us/step - loss: 1034.4619\n",
      "10/10 [==============================] - 0s 718us/step - loss: 1055.6423\n",
      "10/10 [==============================] - 0s 775us/step - loss: 1146.0640\n",
      "10/10 [==============================] - 0s 783us/step - loss: 1102.0392\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1201.8271\n",
      "10/10 [==============================] - 0s 769us/step - loss: 1088.4131\n",
      "10/10 [==============================] - 0s 772us/step - loss: 746.8771\n",
      "10/10 [==============================] - 0s 917us/step - loss: 1176.6840\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1221.6241\n",
      "10/10 [==============================] - 0s 836us/step - loss: 896.6962\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1156.6135\n",
      "10/10 [==============================] - 0s 810us/step - loss: 1265.2845\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1227.7175\n",
      "10/10 [==============================] - 0s 914us/step - loss: 1270.9962\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1025.7229\n",
      "10/10 [==============================] - 0s 847us/step - loss: 1131.3894\n",
      "10/10 [==============================] - 0s 803us/step - loss: 1040.4609\n",
      "10/10 [==============================] - 0s 903us/step - loss: 806.0251\n",
      "10/10 [==============================] - 0s 816us/step - loss: 1231.0052\n",
      "10/10 [==============================] - 0s 769us/step - loss: 994.8920\n",
      "10/10 [==============================] - 0s 776us/step - loss: 1135.3834\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1178.4653\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1230.6908\n",
      "10/10 [==============================] - 0s 837us/step - loss: 1270.5581\n",
      "10/10 [==============================] - 0s 751us/step - loss: 945.7560\n",
      "10/10 [==============================] - 0s 926us/step - loss: 1243.5741\n",
      "10/10 [==============================] - 0s 847us/step - loss: 1107.4196\n",
      "10/10 [==============================] - 0s 970us/step - loss: 957.8817\n"
     ]
    }
   ],
   "source": [
    "rows_B = []\n",
    "for i in range(1,51):\n",
    "    def regression_model(): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "    model.fit(predictors_norm, indicator, validation_data=(X_test, y_test), epochs = 50, verbose = 0)\n",
    "    scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "    rows_B.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value:  0    1100.6742\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0    152.84856\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows_B = pd.DataFrame(rows_B)\n",
    "print(\"Mean Value: \", rows_B.mean(), \"\\n\" \"Standard Deviation Value: \", rows_B.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value Difference:  0    795.25046\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0   -196.561392\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Differences between A and B: \n",
    "\n",
    "print(\"Mean Value Difference: \", (rows_B.mean() - rows.mean()), \"\\n\" \"Standard Deviation Value: \", (rows_B.std() - rows.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking normalized values for our predictor variables only, we can see that the new mean is 1100.6742, which is an increase of 795.25 compared to the mean value for our first MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C: Increasing the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 1357.8741\n",
      "10/10 [==============================] - 0s 932us/step - loss: 1390.2346\n",
      "10/10 [==============================] - 0s 767us/step - loss: 1364.2194\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1265.6790\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1326.1274\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1352.9264\n",
      "10/10 [==============================] - 0s 751us/step - loss: 1357.9973\n",
      "10/10 [==============================] - 0s 807us/step - loss: 1397.0286\n",
      "10/10 [==============================] - 0s 710us/step - loss: 1368.0619\n",
      "10/10 [==============================] - 0s 742us/step - loss: 1340.7109\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1278.0054WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0006s vs `on_test_batch_begin` time: 0.0048s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1384.3558\n",
      "10/10 [==============================] - 0s 769us/step - loss: 1365.1271\n",
      "10/10 [==============================] - 0s 879us/step - loss: 1350.4047\n",
      "10/10 [==============================] - 0s 739us/step - loss: 1356.1792\n",
      "10/10 [==============================] - 0s 941us/step - loss: 1396.4314\n",
      "10/10 [==============================] - 0s 834us/step - loss: 1346.2881\n",
      "10/10 [==============================] - 0s 737us/step - loss: 1379.3347\n",
      "10/10 [==============================] - 0s 781us/step - loss: 1401.1051\n",
      "10/10 [==============================] - 0s 745us/step - loss: 1382.8646\n",
      "10/10 [==============================] - 0s 799us/step - loss: 1356.6206\n",
      "10/10 [==============================] - 0s 908us/step - loss: 1332.5248\n",
      "10/10 [==============================] - 0s 778us/step - loss: 1392.4146\n",
      "10/10 [==============================] - 0s 805us/step - loss: 1398.0634\n",
      "10/10 [==============================] - 0s 725us/step - loss: 1399.1139\n",
      "10/10 [==============================] - 0s 751us/step - loss: 1397.5591\n",
      "10/10 [==============================] - 0s 734us/step - loss: 1375.1598\n",
      "10/10 [==============================] - 0s 768us/step - loss: 1363.1718\n",
      "10/10 [==============================] - 0s 717us/step - loss: 1386.6420\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1346.6423\n",
      "10/10 [==============================] - 0s 854us/step - loss: 1373.4308\n",
      "10/10 [==============================] - 0s 805us/step - loss: 1356.9510\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1310.5592\n",
      "10/10 [==============================] - 0s 803us/step - loss: 1379.9135\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1353.4512\n",
      "10/10 [==============================] - 0s 761us/step - loss: 1378.8427\n",
      "10/10 [==============================] - 0s 777us/step - loss: 1380.6956\n",
      "10/10 [==============================] - 0s 902us/step - loss: 1387.4434\n",
      "10/10 [==============================] - 0s 888us/step - loss: 1382.5825\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1348.0160\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1356.4625\n",
      "10/10 [==============================] - 0s 775us/step - loss: 1379.8831\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1376.6217\n",
      "10/10 [==============================] - 0s 901us/step - loss: 1354.6881\n",
      "10/10 [==============================] - 0s 893us/step - loss: 1396.5806\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1356.1089\n",
      "10/10 [==============================] - 0s 995us/step - loss: 1369.7405\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1372.3541\n",
      "10/10 [==============================] - 0s 860us/step - loss: 1350.0780\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1371.8721\n",
      "10/10 [==============================] - 0s 766us/step - loss: 1401.5608\n"
     ]
    }
   ],
   "source": [
    "rows_C = []\n",
    "for i in range(1,51):\n",
    "    def regression_model(): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "    model.fit(predictors_norm, indicator, validation_data=(X_test, y_test), epochs = 100, verbose = 0)\n",
    "    scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "    rows_C.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value:  0    1367.37397\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0    25.486814\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows_C = pd.DataFrame(rows_C)\n",
    "print(\"Mean Value: \", rows_C.mean(), \"\\n\" \"Standard Deviation Value: \", rows_C.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value Difference:  0    269.044261\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0   -134.208558\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Differences between B and C: \n",
    "\n",
    "print(\"Mean Value Difference: \", (rows_C.mean() - rows_B.mean()), \"\\n\" \"Standard Deviation Value: \", (rows_C.std() - rows_B.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking 100 epochs instead of the 50 in the previous exerccise, we can see that the new mean is 1369.72, which is an increase of 269.04 compared to the mean value for our second MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D: Increasing the number of hidden layersIncrease the number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 797us/step - loss: 1483.1405\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1445.3706\n",
      "10/10 [==============================] - 0s 790us/step - loss: 1452.2634\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1450.2944\n",
      "10/10 [==============================] - 0s 757us/step - loss: 1462.4003\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1449.6140\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1390.6423\n",
      "10/10 [==============================] - 0s 865us/step - loss: 1408.3114\n",
      "10/10 [==============================] - 0s 862us/step - loss: 1444.9498\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1413.1943\n",
      "10/10 [==============================] - 0s 756us/step - loss: 1446.8232\n",
      "10/10 [==============================] - 0s 933us/step - loss: 1415.8759\n",
      "10/10 [==============================] - 0s 805us/step - loss: 1441.0098\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1450.2332\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1450.9163\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1406.9567\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1457.0317\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1439.4421\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1483.6061\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1402.5845\n",
      "10/10 [==============================] - 0s 760us/step - loss: 1400.8665\n",
      "10/10 [==============================] - 0s 748us/step - loss: 1435.5730\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 1463.0024\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1472.4696\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1420.1062\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1530.7260\n",
      "10/10 [==============================] - 0s 966us/step - loss: 1413.2676\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1387.2756\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1431.5846\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1413.7212\n",
      "10/10 [==============================] - 0s 872us/step - loss: 1418.8796\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1402.8323\n",
      "10/10 [==============================] - 0s 778us/step - loss: 1424.2169\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1445.8562\n",
      "10/10 [==============================] - 0s 857us/step - loss: 1441.4141\n",
      "10/10 [==============================] - 0s 819us/step - loss: 1428.1484\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1448.7761\n",
      "10/10 [==============================] - 0s 949us/step - loss: 1488.5288\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1418.5356\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1412.2559\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1454.4921\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1442.4460\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1427.8011\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1441.3506\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1404.5271\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1501.0958\n",
      "10/10 [==============================] - 0s 819us/step - loss: 1463.6107\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1470.9918\n",
      "10/10 [==============================] - 0s 835us/step - loss: 1412.9119\n",
      "10/10 [==============================] - 0s 781us/step - loss: 1448.7815\n"
     ]
    }
   ],
   "source": [
    "rows_D = []\n",
    "for i in range(1,51):\n",
    "    def regression_model(): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(10, activation = \"relu\", input_shape = (n_cols, )))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    model = regression_model()\n",
    "    model.fit(predictors_norm, indicator, validation_data=(X_test, y_test), epochs = 100, verbose = 0)\n",
    "    scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "    rows_D.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value:  0    1439.214116\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0    29.294346\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows_D = pd.DataFrame(rows_D)\n",
    "print(\"Mean Value: \", rows_D.mean(), \"\\n\" \"Standard Deviation Value: \", rows_D.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value Difference:  0    71.840146\n",
      "dtype: float64 \n",
      "Standard Deviation Value:  0    3.807532\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Differences between B and C: \n",
    "\n",
    "print(\"Mean Value Difference: \", (rows_D.mean() - rows_C.mean()), \"\\n\" \"Standard Deviation Value: \", (rows_D.std() - rows_C.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking three artificial neural nets compared to only one in the previous exercise, we can see that the new mean is 1439.21, which is an increase of 71.84 compared to the mean value for our second MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
